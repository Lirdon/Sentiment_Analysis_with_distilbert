{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638a16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-12 13:30:05.028706: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-12 13:30:06.729018: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-12 13:30:06.729059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-12 13:30:06.730185: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-12 13:30:06.737695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import datasets\n",
    "import evaluate\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    DistilBertForSequenceClassification\n",
    ")\n",
    "from peft import PeftModel, LoraConfig, prepare_model_for_kbit_training, get_peft_model, TaskType, AutoPeftModelForSequenceClassification, PeftConfig, PeftMixedModel, AdaLoraConfig\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc307c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openpyxl\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6a/94/a59521de836ef0da54aaf50da6c4da8fb4072fb3053fa71f052fd9399e7a/openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile (from openpyxl)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/96/c2/3dd434b0108730014f1b96fd286040dc3bcb70066346f7e01ec2ac95865f/et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaae3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b2235a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ./distilbert/ and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): AdaLoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): adalora.SVDLinear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n",
       "                  (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n",
       "                  (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n",
       "                )\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): adalora.SVDLinear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n",
       "                  (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n",
       "                  (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./distilbert/\"\n",
    "#peft_path = \"./distilbert-lora-judge/\"\n",
    "peft_path = \"./outputs03121/checkpoint-29000/ada_adapter/\"\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2, ignore_mismatched_sizes=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = PeftModel.from_pretrained(base_model, peft_path)\n",
    "#model = model.merge_and_unload()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa872c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 50000 examples [00:00, 357996.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./dataset\"   #Bohrium数据集：Finetune-dataset-LLMKG\n",
    "dataset = load_dataset(\n",
    "    \"json\", \n",
    "    data_files = {'test': os.path.join(data_dir, 'test_data.jsonl')}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3489770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#hard prompt\n",
    "def get_prompt(instruction, inputs):\n",
    "    #你只能回答问题一次，并确保只回答positive或negative。另外，在生成新的一行前，添加'\\n'来标记。如果你没有按照我的要求生成回答，我会继续提问。\n",
    "    \n",
    "    prompt = \"事件指引: {instruction}\\\n",
    "请仔细阅读以下文本内容，并判断是否包含针对上述事件的投诉或举报信息。\\\n",
    "具体内容: {input}\".format(instruction=instruction, input=inputs)\n",
    "    \n",
    "    #prompt = \"请根据以下任务指引和具体信息描述，判断是否为对某个群体或特定事件的投诉或举报信息。具体的任务指引是{}，信息是{}\" .format(instruction,inputs)\n",
    "    return prompt\n",
    "def tokenizer_func(example):\n",
    "    #example[\"label\"] = [int(item) for item in example[\"label\"]]\n",
    "    #print(example[\"category_description\"])\n",
    "    prompt = get_prompt(example[\"category_description\"], example[\"text\"])\n",
    "    return tokenizer(prompt, padding=\"max_length\", truncation=\"longest_first\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c98ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_func(example):\n",
    "    return tokenizer(example[\"category_description\"], example[\"text\"], padding=\"max_length\", truncation=\"longest_first\", max_length=492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7ac4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50000/50000 [00:08<00:00, 5962.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset[\"test\"].map(tokenizer_func, batched=True)\n",
    "test_dataset = test_dataset.remove_columns([\"category_description\",\"text\"])\n",
    "test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d982ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(test_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99771cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=64, pin_memory=True)\n",
    "@torch.no_grad()\n",
    "def eval(inputs):\n",
    "    #inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs[\"input_ids\"]=inputs[\"input_ids\"].cuda()\n",
    "    inputs[\"attention_mask\"]=inputs[\"attention_mask\"].cuda()\n",
    "    logits = model(**inputs).logits\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992ee6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_write(output_file):\n",
    "    out_excel = []\n",
    "    for inputs in tqdm(test_dataloader):\n",
    "        output = eval(inputs).cpu().numpy().tolist()\n",
    "        out_excel.append(output)\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    for sublist in out_excel:\n",
    "        for item in sublist:\n",
    "            ws.append([item])\n",
    "    wb.save(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 689/782 [01:53<00:15,  6.14it/s]"
     ]
    }
   ],
   "source": [
    "output_file = \"output.xlsx\"\n",
    "excel_write(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c73781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
